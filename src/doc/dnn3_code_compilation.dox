// doc/dnn3_code_compilation.dox


// Copyright 2015   Johns Hopkins University (author: Daniel Povey)

// See ../../COPYING for clarification regarding multiple authors
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at

//  http://www.apache.org/licenses/LICENSE-2.0

// THIS CODE IS PROVIDED *AS IS* BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, EITHER EXPRESS OR IMPLIED, INCLUDING WITHOUT LIMITATION ANY IMPLIED
// WARRANTIES OR CONDITIONS OF TITLE, FITNESS FOR A PARTICULAR PURPOSE,
// MERCHANTABLITY OR NON-INFRINGEMENT.
// See the Apache 2 License for the specific language governing permissions and
// limitations under the License.

namespace kaldi {
namespace nnet3 {

/**
  \page dnn3_code_compilation Compilation in the "nnet3" setup

  \section dnn3_code_compilation_intro Introduction

  This page covers the compilation process in the "nnet3" setup.  It will
  generally only be of interest to those who want to understand the internals of
  the framework.

  - Up: \ref dnn3.
  - Previous: \ref dnn3_code_data_types
  - Next: \ref dnn3_code_optimization

  \section dnn3_compile_overview Overview of compilation

   We assume that the reader is familiar with the data types introduced in
   \ref dnn3_code_data_types.  The compilation process is something that
   takes as input an Nnet and a ComputationRequest, and outputs a
   NnetComputation.  The ComputationRequest includes a representation of
   what output indexes are requested and what input indexes are available;
   the reason why we don't just supply the output indexes and let the compiler
   work out what input indexes are required, is that some networks such as RNNs
   may consume an arbitrary amount of input to produce a given output.

   Something that might be considered a part of the compilation process, but
   which we discuss in a separate page, is code optimization: see \ref dnn3_code_optimization.

   This page includes [TODO]
    

  \section dnn3_compile_graph Creating the computation graph


   \subsection dnn3_compile_graph_graph Details of ComputationGraph

   We previously gave a brief introduction to struct ComputationGraph, but
  here we provide a few more details.  Remember that the ComputationGraph
  maps back and forth between Cindexes and integer cindex_ids for efficiency.
  We show just the data members of ComputationGraph here (remember that
in C++, a struct is just a class whose members are public by default):
\verbatim
struct ComputationGraph {
  // The mapping of cindex_id to Cindex.
  std::vector<Cindex> cindexes;

  // For each Cindex this tells us whether it was provided as an input to the
  // computation.
  std::vector<bool> is_input;

  // dependencies[cindex_id] gives you the list of other cindex_ids that this
  // particular cindex_id directly depends on to compute it.
  std::vector<std::vector<int32> > dependencies;
private:
  // Maps each Cindex to an integer cindex_id: reverse mapping of "cindexes".
  // Must be accessed via the GetCindexId() function.
  unordered_map<Cindex, int32, CindexHasher> cindex_to_cindex_id_;
};
\endverbatim
 The most important thing is that a ComputationGraph maps back and forth
 between Cindexes and cindex_ids (integers), and stores a list of "dependencies",
 saying for each cindex_id which other cindex_ids are required to compute it.
 The exact meaning of "dependencies" depends on the stage of the compilation.
 At early stages it contains all cindex_ids corresponding to Cindexes that
 were returned by the \ref Descriptor::GetDependencies() "GetDependencies()"
 function of class Descriptor.  Later on it is pruned back to only those dependencies
 that are actually used in the computation.
 Note that Components also have a similar \ref Component::GetDependencies() "GetDependencies()"
 function, and an \ref Component::IsComputable() "IsComputable()" function, like Descriptors.
 However, this only does someathing interesting in the case of non-simple Components.


 The ComputationGraph also has a vector "is_input", saying whether each cindex_id
 is an input to the computation.  This might seem redundant, because we could just
 look up whether its node is of type kInput.  It is needed because we have actually
 designed the framework so that you can provide previously computed values of nodes
 of type kComponent: this has an envisaged use in online decoding for speech 
 recognition with things like RNNs.

 \subsection dnn3_compile_graph_building  Building the ComputationGraph


  \subsubsection dnn3_compile_graph_building_intro Introduction

 Class ComputationGraphBuilder is responsible for building the ComputationGraph.
 In the simple case where there are no optional dependencies, the process is
 quite simple.   (By optional dependencies, we mean descriptors
 with <code>Failover(X,Y)</code> or <code>IfDefined(X)</code>, or certain non-simple
 Components).  The simple version of the process is that we start with requested outputs
 of the network, compute their dependencies and add them to the ComputationGraph,
 and keep working backward adding dependencies until we hit input nodes.  At that
 point, hopefully all Cindexes we require at input nodes are ones that have been 
 supplied in the ComputationRequest; if they are not supplied, we would have to
 say that the computation is not possible.
 

 \subsubsection dnn3_compile_graph_building_basic  Basic algorithm

 Here we describe a basic algorithm which is <em>not</em> what we use but which
 serves to motivate the actual algorithm.  While building the computation graph
 we need to be able to work out whether each Cindex is computable from supplied
 inputs.  (We will use the terms Cindex and cindex_id fairly interchangeably,
 because there is a one-to-one mapping).  One simple and natural and algorithm
 would be as follows:
    - First follow back all possible dependencies from the
      output using the <code>GetDependencies()</code> functions of Descriptors and Components.
    - In the opposite direction, starting from the input, work out which Cindexes are
      computable (using <code>IsComputable()</code>), and prune back the dependencies to just those that
      participate in the computation.
    - Check that all requested outputs were computable.
    - Prune away all cindex_ids that are not actually necessary to compute the
      outputs.
    .
 However, this algorithm wouldn't work in all cases of interest, for instance
 RNNs.  The problem is that the first phase (following back all possible dependencies)
 would run forever, with t approaching -\infin.  

 \subsubsection dnn3_compile_graph_building_idea Motivation for the algorithm we use

 Instead we need a slightly more sophisticated algorithm.  We haven't proven that this algorithm
 would always terminate in all possible cases of interest, but it seems likely to terminate in all
 the cases we have in mind.  Consider the case of an RNN where some recurrent layer has a
 dependency that goes back to time t-1, and the input starts at t = 0.  Following dependencies
 will take t all the way back to -\infin, but we should be able to figure out that
 those hidden-layer Cindexes for negative t are never going to participate in the computation,
 because if we follow <em>their</em> dependencies back to the input we will see that the
 corresponding inputs were not supplied, so they are not computable.  The way we make use
 of this to avoid recursing to -\infin is to note that if a Cindex is not computable,
 there is no point following its dependencies back because we know they will never be used.
 The problem is that this is a chicken-and-egg situation because before we process the
 dependencies of a Cindex we don't <em>know</em> that it's not computable.

 \subsubsection dnn3_compile_graph_building_real The algorithm we use

 The way we solve this problem is as follows.  We assign to each Cindex an enum 
 \ref ComputationGraphBuilder::ComputableInfo "ComputableInfo", defined as:
\verbatim
  enum ComputableInfo {
    kUnknown = 0,
    kComputable = 1,
    kNotComputable = 2,
    kWillNotCompute = 3
  };
\endverbatim
 whose meaning is as follows:
  - kUnknown: we are not yet sure whether this Cindex is computable
  - kComputable: we know that this Cindex is computable
  - kNotComputable: we know that this Cindex is not computable
  - kWillNotCompute: we are not going to compute this Cindex regardless of whether
    it's computable, because we have determined that it is not usable.  Treated the same
    as kNotComputable for most purposes.
    .
The way we determine whether a Cindex is usable is as follows.
We assign to each Cindex an integer \ref ComputationGraphBuilder::usable_count_ "usable_count" which functions
a little like a reference-count in memory management.  If the \ref ComputationGraphBuilder::usable_count_ "usable_count" for a Cindex
is >0, it means that that that Cindex might possibly partipate in the final computation.
We ensure that the \ref ComputationGraphBuilder::usable_count_ "usable_count" always has
a value determined by the following rules:
  - 1 if this Cindex is a requested output in the ComputationRequest.  Otherwise..
  - The number of other Cindexes j such that:
     - The ComputableInfo of j is not kNotComputable, and
     - The usable_count of j is greater than zero, and
     - This Cindex is a dependency of j in the computation graph.
     .
  .
The way we avoid infinitely recursing in the processing of dependencies is that 
if the usable_count of a Cindex is zero we set its state to kWillNotCompute and
then we refrain from adding its dependencies to the computation graph.
For this to work, we make sure to process the dependencies in breadth-first
order: that is, we process dependencies at one hop from the output, then two
hops from the output, and so on.  This avoids the case where, in the RNN, we might
process the hidden layer all the way back to t = -\infin before noticing that
the corresponding inputs were not available.

Class ComputationGraphBuilder maintains two queues: one for Cindexes that
we haven't yet added their dependencies to the graph, and one 
(\ref ComputationGraphBuilder::computable_queue_ "computable_queue_") for
Cindexes such that we need to re-evaluate whether they are computable
(i.e. update their ComputableInfo).  When the ComputableInfo of a Cindex
changes, we need to re-check the ComputableInfo of Cindexes that depend on it,
and to do so we add them to \ref ComputationGraphBuilder::computable_queue_ "computable_queue_".

 
 \subsubsection dnn3_compile_graph_building_interface Interface of ComputationGraphBuilder

We list the most important parts of the public interface of ComputationGraph Builder below;
it should be quite self-explanatory.
\verbatim
class ComputationGraphBuilder {
 public:
  ComputationGraphBuilder(const Nnet &nnet,
                          const ComputationRequest &request,
                          ComputationGraph *graph);
  // Does the initial computation (populating the graph and computing
  // whether each required cindex_id is computable), without the pruning.
  void Compute();
  // Returns true if all requested outputs are computable.  To be called after
  // Compute() but before Prune(().
  bool AllOutputsAreComputable();
  // Removed unused Cinndexes from the graph.
  void Prune();
  ...
};
\endverbatim


\section dnn3_compile_steps  Organizing the computation into steps

 \subsection dnn3_compile_steps_intro Introduction to steps

Once we have the computation graph, we have enough information in principle to
execute the computation without doing much more work.  We could sort the
Cindexes in topological order in the computation graph, and individually
evaluate each Cindex using its dependencies as inputs.  Unfortunately this
wouldn't be very efficient because matrix operations don't reach their full
efficiency unless they are operating on quite large matrices; this is
particularly true when using GPUs.  So what we want to do is to group
the Cindexes into batches such that the Cindexes in the same batch can
all be computed at the same time.  This batch is going to be called a "step",
and it will roughly correspond to one command in the NnetComputation.

We are going to arrange the set of all cindex_ids in the computation into a sequence
of steps, with the following properties:
  - All cindex_ids within a given step correspond to the same node in the graph
  - All dependencies of cindex_ids within a given step have been computed in 
    earlier steps.
  .
There are also some extra, more obscure properties that the sequence of steps
must satisfy:
  - Any input or output in the ComputationRequest must be in one step, with the
    Indexes in the same order as specified in the ComputationRequest.  (Note:
    inputs can be for nodes of type kComponent as well as kInput).
  - If this step corresponds to a node of type kComponent (and does not correspond to
    an input in the ComputationRequest), then the immediately 
    preceding step must correspond to a node of type kDescriptor, and the sequence of
    Indexes in the two steps must be identical.
  .
The reason for the last rule is to ensure that the Component can use the output
of the Descriptor directly as its input, without any additional reordering or
regrouping (since such reordering and regrouping is, by design, the
responsibility of the Descriptors).  Because of this last rule, it is possible
in principle for a cindex_id from a node of type kDescriptor to appear
separately in more than one different step, although this could only happen if
we were using non-simple Components.

 \subsection dnn3_compile_steps_creating  Creating the sequence of steps (basic algorithm)

Here we describe a basic algorithm for creating the sequence of steps
that we <em>do not use</em>, but will serve to motivate the actual algorithm that
we'll describe later.
This basic algorithm would be:
  - First put aside Cindexes corresponding to input and output nodes, 
    separate them by node-index, order within each of those steps
    to the same order as the ComputationRequests, and put them on the side.
  - Next process the intermediate Cindexes that are not inputs or outputs as follows:
    - Take the remaining Cindexes and arrange them into sets called "phases"
      where the first phase contains all Cindexes that depend only on inputs;
      and in general the n'th phase contains all remaining Cindexes that depend
      only on quantities present in phases less than n.
    - Break each of the phases above into steps in order to ensure that each
      step corresponds to only one node-index
    - Temporarily remove any of these steps corresponding to component-input
      nodes (i.e. kDescriptor nodes immediately preceding kComponent nodes).
    - Order the remaining steps correctly by using the ordering operator of
      struct Index.
    - Recreate the steps for component-input nodes while ensuring they satisfy
      all our properties, as follows:
       - For each step of type kComponent, compute the set of all its
         dependencies using the "dependencies" member of the ComputationGraph.
       - Order them using the ordering operator of struct Index.  (for simple
         Components this ensures they are in the same order as the output
         of the Component).
       - (Obscure feature): non-simple Components that want to reorder their
         inputs are allowed to do so at this point; see Component::ReorderIndexes().
       - Place this step immediately before the corresponding step of the Component.
  - Order all the steps so that inputs come first, intermediate steps come next, 
    and output-steps come last.
  
 The problem with the algorithm described above is that it would end up
 splitting things into to many steps.  For instance, imagine that we have a recurrent
 layer followed by a standard feedforward layer.  The recurrent layer has to be
 split up into as many steps as there are time indexes, but the above algorithm
 would also split up the computation of the the fully-connected layer into many steps
 because those Cindexes become computable immediately after the corresponding Cindexes
 for the recurrent layer.  What we want it for it to do all computation of the
 recurrent layer, then do the computation for the fully-connected layer in one step.

 \subsection dnn3_compile_steps_creating  Creating the sequence of steps (actual algorithm)

 In order to handle architectures like RNNs without creating an excessive number
 of computation steps, we first do some graph-theoretic processing on the neural
 network itself to determine the order in which we can process nodes in the
 graph.  We can express the neural network itself as a directed graph on nodes,
 where there is an arc from node A to node B if node B ever refers to quantities
 from node A (see \ref NnetToDirectedGraph()).  

 The function \ref ComputeNnetComputationEpochs() produces a mapping from nodes
 to epoch indexes, where nodes that are part of the same strongly connected
 component (SCC) in the graph (e.g. nodes that are part of the recurrency in an
 RNN) go to the same epoch, but nodes that are in an earlier epoch can always
 be computed first.  That is, roughly the epoch will correspond to the layer index
 in the neural net.

 The actual algorithm, then, produces three progressively more specific orderings
 of Cindexes: first epochs, then phases, then steps.  We use essentially the algorithm
 described in the previous section, except modified to respect the division into
 epochs.   We first call \ref ComputeComputationPhases() to divide the cindexes
 into phases, and then \ref ComputeComputationSteps() which works out the actual
 steps.
 

\section dnn3_compile_compiler Class Compiler

\subsection dnn3_compile_compiler_intro  Introduction to class Compiler

The Compiler class has overall responsibility for turning the
ComputationRequest, together with an Nnet, into a NnetComputation.  Internally
it first creates a ComputationGraph and a sequence of steps using the classes
and functions we have introduced above.

Its public interface is very simple:
\verbatim
class Compiler {
 public:
  Compiler(const ComputationRequest &request,
           const Nnet &nnet);
  
  void CreateComputation(const CompilerOptions &opts,
                         NnetComputation *computation);
  ...
};
\endverbatim

Most of the work of this class happens in its \ref Compiler::CreateComputation "CreateComputation()"
function, and the code for this is here:
\verbatim
void Compiler::CreateComputation(const CompilerOptions &opts,
                                 NnetComputation *computation) {
  ComputationGraphBuilder builder(nnet_, request_, &graph_);
  builder.Compute();
  builder.Prune();

  // see function declaration's comment for meaning of "phases".
  std::vector<std::vector<int32> > phases;
  ComputeComputationPhases(nnet_, graph_, &phases);
  std::vector<std::vector<int32> > steps;
  ComputeComputationSteps(nnet_, request_, phases, &graph_, &steps);
  phases.clear();
  CreateLocationInfo(steps);
  std::vector<bool> deriv_needed;
  ComputeDerivNeeded(steps, &deriv_needed);
  CreateStepInfo(deriv_needed, &steps, computation);
  AddCommands(deriv_needed, computation);
  if (opts.output_debug_info)
    OutputDebugInfo(computation);
}  
\endverbatim
The parts of this up to ComputeComputationSteps() are things that we have already discussed.

[UNFINISHED]

 Next: \ref dnn3_code_optimization

*/

}
}
